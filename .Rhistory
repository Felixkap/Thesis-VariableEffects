se.method = 'jack_cov',
predict.all = T,
inbag.counts = rf$inbag.counts)
### Computing Predictions
# Using f_hat and sample mean&variance of X
predictions.rf <- rowMeans(rf.predict$predictions)
# Using f and true mean&variance of X
predictions.f.true <- eval(formula_p, new_data.true)
var_effects[v] <- ((predictions.rf[5] - predictions.rf[3]) - (predictions.rf[6] - predictions.rf[4])) / (-4*k^2*sd(x[,interaction_term[1]])*sd(x[,interaction_term[2]]))
var_effects_true[v] <- ((predictions.f.true[5] - predictions.f.true[3]) - (predictions.f.true[6] - predictions.f.true[4])) / (-4*k^2*true_s[interaction_term[1]]*true_s[interaction_term[2]])
effect.var <- pmax((sum(diag(rf.predict$cov))
- 2*rf.predict$cov[2,1]
- 2*rf.predict$cov[3,1] + 2*rf.predict$cov[3,2]
+ 2*rf.predict$cov[4,1] - 2*rf.predict$cov[4,2] - 2*rf.predict$cov[4,3]) /  ((-4*k^2*sd(x[,interaction_term[1]])*sd(x[,interaction_term[2]])))^2, 0)
var_effects_se[v] <- sqrt(effect.var)
}
}
}
result_list[['effects.rf']][rep,] <- var_effects
result_list[['effects.f.true']][rep,] <- var_effects_true
result_list[['effects.se.rf']][rep,] <- var_effects_se
}
return(result_list)
}
res <- lapply(scenarios, sim_once)
scenarios
set.seed(123)
N <- c(400) ; num.trees <- 2000 ; repeats <- 10; cor <- c(0)
k <- c(0.2, 1); node_size <- c(1); reps <- 100
formula <- c("2*x.1+4*x.2-3*x.3+2.2*x.4-1.5*x.5")
longest_latex_formula <- "2x_1+4x_2-3x_3+2.2x_4-1.5x_5"
scenarios <- data.frame(expand.grid(N, num.trees, formulas, repeats,
cor, k, node_size))
colnames(scenarios) = c("N", "N_Trees", "Formula", "Repeats",
"Correlation", "k", "Node_Size")
scenarios$k_idx <- (scenarios$k == unique(scenarios$k)[1])
scenarios[,"Formula"] <- as.character(scenarios[,"Formula"]) ### Formula became Factor
scenarios["Longest_Latex_formula"] <- longest_latex_formula
scenarios <- split(scenarios, seq(nrow(scenarios)))
sim_once <- function(k, N, num.trees, cor, formula, node_size, reps){
### Simulate Data
n_vars <- length(unique(unlist(str_extract_all(formula,"x.[0-9]+")))) # Number of variables
if (n_vars == 1) {
# Normal Distribution with Mean 0 and Variance 1
x <- data.frame(x.1 = rnorm(N, 0, 1))
} else{
# Multivariate Normal Distribution with Mean Vector 0 and diagonal Variance Covariance Matrix
x <- data.frame(x = rmvnorm(N, mean = rep(0, n_vars), sigma = CSgenerate(n_vars, cor)))
}
# Get interaction terms
all_terms_t <- unlist(strsplit(formula, "(?<=.)(?=[+])|(?<=.)(?=[-])",perl = TRUE))
all_terms <- character()
idx <- 1
for (term in 1:length(all_terms_t)) {
if ((str_count(all_terms_t[term],"\\(") >= 1) & (str_count(all_terms_t[term],"\\)") == 0)) {
all_terms[idx] <- paste0(all_terms_t[term], all_terms_t[term+1])
idx = idx + 1
} else if ((str_count(all_terms_t[term],"\\(") == 0) & (str_count(all_terms_t[term],"\\)") >= 1)){
} else {
all_terms[idx] <- all_terms_t[term]
idx <- idx + 1
}
}
n_coefs <- length(all_terms)
for (term in all_terms) {
if (length(unique(unlist(str_extract_all(term,"x.[0-9]+")))) > 1) {
interaction_term <- unique(unlist(str_extract_all(term,"x.[0-9]+")))
}
}
formula_p <- parse(text = formula)
y <- eval(formula_p, x) + rnorm(N, 0, 1)
data <- data.frame(cbind(x, y))
# Estimated Variable Means
x_bar <- colMeans(x)
# True Variable Means and Standard Deviations
true_mean <- rep(x = 0, times = n_vars)
names(true_mean) <- unique(unlist(str_extract_all(formula,"x.[0-9]+")))
true_s <- rep(x = 1, times = n_vars)
names(true_s) <- unique(unlist(str_extract_all(formula,"x.[0-9]+")))
list_names <- c('effects.rf','effects.f.true', 'effects.se.rf')
result_list <- vector(mode = 'list', length = length(list_names))
result_list <- lapply(X = 1:length(list_names), FUN = function(x){
init <- matrix(data = 0, nrow = reps, ncol = n_coefs)
colnames(init) <- extract_terms(formula)
result_list[[x]] <- init
})
names(result_list) <- list_names
for (rep in 1:reps) {
rf <- ranger( formula = y ~ .,
data = data,
num.trees = num.trees,
keep.inbag = T,
oob.error = F, # Save computational time
min.node.size = node_size)
var_effects <- numeric(n_coefs)
var_effects_se <- numeric(n_coefs)
var_effects_true <- numeric(n_coefs)
for (v in 1:n_coefs) {
# New data points based on estimated variable means and standard deviations
x_a <- replace(x_bar, v, x_bar[v] - k*sd(x[,v]))
x_b <- replace(x_bar, v, x_bar[v] + k*sd(x[,v]))
# New data points based on true variable means and standard deviations
x_a.true <- replace(true_mean, v, true_mean[v] - k*true_s[v])
x_b.true <- replace(true_mean, v, true_mean[v] + k*true_s[v])
new_data <- data.frame(rbind(x_a, x_b))
new_data.true <- data.frame(rbind(x_a.true, x_b.true))
rf.predict <- RangerForestPredict(rf$forest,
new_data,
type='se',
se.method = 'jack_cov',
predict.all = T,
inbag.counts = rf$inbag.counts)
# Using f_hat and sample mean&variance of X
predictions.rf <- rowMeans(rf.predict$predictions)
# Using f and true mean&variance of X
predictions.f.true <- eval(formula_p, new_data.true)
# Using f_hat predictions based on sample mean&variance of X
var_effects[v] <- (predictions.rf[2] - predictions.rf[1]) / (2*k*sd(x[,v]))
# Using f predictions based on true mean&variance of X
var_effects_true[v] <- (predictions.f.true[2] - predictions.f.true[1]) / (2*k*true_s[v])
effect.var <- pmax((rf.predict$cov[1,1] + rf.predict$cov[2,2]
- 2*rf.predict$cov[1,2]) /  (2*k*sd(x[,v]))^2, 0)
var_effects_se[v] <- sqrt(effect.var)
if (exists('interaction_term')) {
if (v == as.numeric(gsub(".*?([0-9]+).*", "\\1", interaction_term[1]))) {
# New data points based on estimated variable means and standard deviations
x_a <- replace(x_bar, v, x_bar[v] - k*sd(x[,v]))
x_b <- replace(x_bar, v, x_bar[v] + k*sd(x[,v]))
# New data points based on true variable means and standard deviations
x_a.true <- replace(true_mean, v, true_mean[v] - k*true_s[v])
x_b.true <- replace(true_mean, v, true_mean[v] + k*true_s[v])
x_a1 <- replace(x_a, n_vars, x_bar[v] - k*sd(x[,v]))
x_b1 <- replace(x_b, n_vars, x_bar[v] - k*sd(x[,v]))
x_a2 <- replace(x_a, n_vars, x_bar[v] + k*sd(x[,v]))
x_b2 <- replace(x_b, n_vars, x_bar[v] + k*sd(x[,v]))
x_a1.true <- replace(x_a.true, n_vars, true_mean[v] - k*true_s[v])
x_b1.true <- replace(x_b.true, n_vars, true_mean[v] - k*true_s[v])
x_a2.true <- replace(x_a.true, n_vars, true_mean[v] + k*true_s[v])
x_b2.true <- replace(x_b.true, n_vars, true_mean[v] + k*true_s[v])
new_data <- data.frame(rbind(x_a, x_b,
x_a1, x_b1,
x_a2, x_b2))
new_data.true <- data.frame(rbind(x_a.true, x_b.true,
x_a1.true, x_b1.true,
x_a2.true, x_b2.true))
rf.predict <- RangerForestPredict(rf$forest,
new_data,
type='se',
se.method = 'jack_cov',
predict.all = T,
inbag.counts = rf$inbag.counts)
### Computing Predictions
# Using f_hat and sample mean&variance of X
predictions.rf <- rowMeans(rf.predict$predictions)
# Using f and true mean&variance of X
predictions.f.true <- eval(formula_p, new_data.true)
var_effects[v] <- ((predictions.rf[5] - predictions.rf[3]) - (predictions.rf[6] - predictions.rf[4])) / (-4*k^2*sd(x[,interaction_term[1]])*sd(x[,interaction_term[2]]))
var_effects_true[v] <- ((predictions.f.true[5] - predictions.f.true[3]) - (predictions.f.true[6] - predictions.f.true[4])) / (-4*k^2*true_s[interaction_term[1]]*true_s[interaction_term[2]])
effect.var <- pmax((sum(diag(rf.predict$cov))
- 2*rf.predict$cov[2,1]
- 2*rf.predict$cov[3,1] + 2*rf.predict$cov[3,2]
+ 2*rf.predict$cov[4,1] - 2*rf.predict$cov[4,2] - 2*rf.predict$cov[4,3]) /  ((-4*k^2*sd(x[,interaction_term[1]])*sd(x[,interaction_term[2]])))^2, 0)
var_effects_se[v] <- sqrt(effect.var)
}
}
}
result_list[['effects.rf']][rep,] <- var_effects
result_list[['effects.f.true']][rep,] <- var_effects_true
result_list[['effects.se.rf']][rep,] <- var_effects_se
}
return(result_list)
}
res <- lapply(scenarios, sim_once)
res <- sim_once(k, N, num.trees, cor, formula, node_size, reps)
rm(list=ls())
library(Matrix)
library(tidyverse)
library(ggplot2)
library(ggpubr)
library(ranger)
library(MixMatrix)
library(mvtnorm)
library(stringr)
library(ggh4x)
library(iml)
library(ALEPlot)
source('C:/Users/feix_/iCloudDrive/Studium Master/CQM - Thesis Internship/Thesis-VariableEffects/RangerPredictFunction.R')
source('C:/Users/feix_/iCloudDrive/Studium Master/CQM - Thesis Internship/Thesis-VariableEffects/Helper.R')
set.seed(123)
N <- c(400) ; num.trees <- 2000 ; reps <- 100; cor <- c(0)
k <- c(0.2, 1); node_size <- c(1)
formulas <- c("2*x.1+4*x.2-3*x.3+2.2*x.4-1.5*x.5")
longest_latex_formula <- "2x_1+4x_2-3x_3+2.2x_4-1.5x_5"
scenarios <- data.frame(expand.grid(N, num.trees, formulas, reps,
cor, k, node_size))
colnames(scenarios) = c("N", "N_Trees", "Formula", "Reps",
"Correlation", "k", "Node_Size")
scenarios$k_idx <- (scenarios$k == unique(scenarios$k)[1])
scenarios[,"Formula"] <- as.character(scenarios[,"Formula"]) ### Formula became Factor
scenarios["Longest_Latex_formula"] <- longest_latex_formula
scenarios <- split(scenarios, seq(nrow(scenarios)))
sim <- function(scenario){
k <- scenario[['k']]
N <- scenario[['N']]
num.trees <- scenario[['N_Trees']]
cor <- scenario[['Correlation']]
formula <- scenario[['Formula']]
node_size <- scenario[['Node_Size']]
reps <- scenario[['Reps']]
### Simulate Data
n_vars <- length(unique(unlist(str_extract_all(formula,"x.[0-9]+")))) # Number of variables
if (n_vars == 1) {
# Normal Distribution with Mean 0 and Variance 1
x <- data.frame(x.1 = rnorm(N, 0, 1))
} else{
# Multivariate Normal Distribution with Mean Vector 0 and diagonal Variance Covariance Matrix
x <- data.frame(x = rmvnorm(N, mean = rep(0, n_vars), sigma = CSgenerate(n_vars, cor)))
}
# Get interaction terms
all_terms_t <- unlist(strsplit(formula, "(?<=.)(?=[+])|(?<=.)(?=[-])",perl = TRUE))
all_terms <- character()
idx <- 1
for (term in 1:length(all_terms_t)) {
if ((str_count(all_terms_t[term],"\\(") >= 1) & (str_count(all_terms_t[term],"\\)") == 0)) {
all_terms[idx] <- paste0(all_terms_t[term], all_terms_t[term+1])
idx = idx + 1
} else if ((str_count(all_terms_t[term],"\\(") == 0) & (str_count(all_terms_t[term],"\\)") >= 1)){
} else {
all_terms[idx] <- all_terms_t[term]
idx <- idx + 1
}
}
n_coefs <- length(all_terms)
for (term in all_terms) {
if (length(unique(unlist(str_extract_all(term,"x.[0-9]+")))) > 1) {
interaction_term <- unique(unlist(str_extract_all(term,"x.[0-9]+")))
}
}
formula_p <- parse(text = formula)
y <- eval(formula_p, x) + rnorm(N, 0, 1)
data <- data.frame(cbind(x, y))
# Estimated Variable Means
x_bar <- colMeans(x)
# True Variable Means and Standard Deviations
true_mean <- rep(x = 0, times = n_vars)
names(true_mean) <- unique(unlist(str_extract_all(formula,"x.[0-9]+")))
true_s <- rep(x = 1, times = n_vars)
names(true_s) <- unique(unlist(str_extract_all(formula,"x.[0-9]+")))
list_names <- c('effects.rf','effects.f.true', 'effects.se.rf')
result_list <- vector(mode = 'list', length = length(list_names))
result_list <- lapply(X = 1:length(list_names), FUN = function(x){
init <- matrix(data = 0, nrow = reps, ncol = n_coefs)
colnames(init) <- extract_terms(formula)
result_list[[x]] <- init
})
names(result_list) <- list_names
for (rep in 1:reps) {
rf <- ranger( formula = y ~ .,
data = data,
num.trees = num.trees,
keep.inbag = T,
oob.error = F, # Save computational time
min.node.size = node_size)
var_effects <- numeric(n_coefs)
var_effects_se <- numeric(n_coefs)
var_effects_true <- numeric(n_coefs)
for (v in 1:n_coefs) {
# New data points based on estimated variable means and standard deviations
x_a <- replace(x_bar, v, x_bar[v] - k*sd(x[,v]))
x_b <- replace(x_bar, v, x_bar[v] + k*sd(x[,v]))
# New data points based on true variable means and standard deviations
x_a.true <- replace(true_mean, v, true_mean[v] - k*true_s[v])
x_b.true <- replace(true_mean, v, true_mean[v] + k*true_s[v])
new_data <- data.frame(rbind(x_a, x_b))
new_data.true <- data.frame(rbind(x_a.true, x_b.true))
rf.predict <- RangerForestPredict(rf$forest,
new_data,
type='se',
se.method = 'jack_cov',
predict.all = T,
inbag.counts = rf$inbag.counts)
# Using f_hat and sample mean&variance of X
predictions.rf <- rowMeans(rf.predict$predictions)
# Using f and true mean&variance of X
predictions.f.true <- eval(formula_p, new_data.true)
# Using f_hat predictions based on sample mean&variance of X
var_effects[v] <- (predictions.rf[2] - predictions.rf[1]) / (2*k*sd(x[,v]))
# Using f predictions based on true mean&variance of X
var_effects_true[v] <- (predictions.f.true[2] - predictions.f.true[1]) / (2*k*true_s[v])
effect.var <- pmax((rf.predict$cov[1,1] + rf.predict$cov[2,2]
- 2*rf.predict$cov[1,2]) /  (2*k*sd(x[,v]))^2, 0)
var_effects_se[v] <- sqrt(effect.var)
if (exists('interaction_term')) {
if (v == as.numeric(gsub(".*?([0-9]+).*", "\\1", interaction_term[1]))) {
# New data points based on estimated variable means and standard deviations
x_a <- replace(x_bar, v, x_bar[v] - k*sd(x[,v]))
x_b <- replace(x_bar, v, x_bar[v] + k*sd(x[,v]))
# New data points based on true variable means and standard deviations
x_a.true <- replace(true_mean, v, true_mean[v] - k*true_s[v])
x_b.true <- replace(true_mean, v, true_mean[v] + k*true_s[v])
x_a1 <- replace(x_a, n_vars, x_bar[v] - k*sd(x[,v]))
x_b1 <- replace(x_b, n_vars, x_bar[v] - k*sd(x[,v]))
x_a2 <- replace(x_a, n_vars, x_bar[v] + k*sd(x[,v]))
x_b2 <- replace(x_b, n_vars, x_bar[v] + k*sd(x[,v]))
x_a1.true <- replace(x_a.true, n_vars, true_mean[v] - k*true_s[v])
x_b1.true <- replace(x_b.true, n_vars, true_mean[v] - k*true_s[v])
x_a2.true <- replace(x_a.true, n_vars, true_mean[v] + k*true_s[v])
x_b2.true <- replace(x_b.true, n_vars, true_mean[v] + k*true_s[v])
new_data <- data.frame(rbind(x_a, x_b,
x_a1, x_b1,
x_a2, x_b2))
new_data.true <- data.frame(rbind(x_a.true, x_b.true,
x_a1.true, x_b1.true,
x_a2.true, x_b2.true))
rf.predict <- RangerForestPredict(rf$forest,
new_data,
type='se',
se.method = 'jack_cov',
predict.all = T,
inbag.counts = rf$inbag.counts)
### Computing Predictions
# Using f_hat and sample mean&variance of X
predictions.rf <- rowMeans(rf.predict$predictions)
# Using f and true mean&variance of X
predictions.f.true <- eval(formula_p, new_data.true)
var_effects[v] <- ((predictions.rf[5] - predictions.rf[3]) - (predictions.rf[6] - predictions.rf[4])) / (-4*k^2*sd(x[,interaction_term[1]])*sd(x[,interaction_term[2]]))
var_effects_true[v] <- ((predictions.f.true[5] - predictions.f.true[3]) - (predictions.f.true[6] - predictions.f.true[4])) / (-4*k^2*true_s[interaction_term[1]]*true_s[interaction_term[2]])
effect.var <- pmax((sum(diag(rf.predict$cov))
- 2*rf.predict$cov[2,1]
- 2*rf.predict$cov[3,1] + 2*rf.predict$cov[3,2]
+ 2*rf.predict$cov[4,1] - 2*rf.predict$cov[4,2] - 2*rf.predict$cov[4,3]) /  ((-4*k^2*sd(x[,interaction_term[1]])*sd(x[,interaction_term[2]])))^2, 0)
var_effects_se[v] <- sqrt(effect.var)
}
}
}
result_list[['effects.rf']][rep,] <- var_effects
result_list[['effects.f.true']][rep,] <- var_effects_true
result_list[['effects.se.rf']][rep,] <- var_effects_se
}
return(result_list)
}
res <- lapply(scenarios, sim_once)
res <- lapply(scenarios, sim)
rm(list=ls())
library(Matrix)
library(tidyverse)
library(ggplot2)
library(ggpubr)
library(ranger)
library(MixMatrix)
library(mvtnorm)
library(stringr)
library(ggh4x)
library(iml)
library(ALEPlot)
source('C:/Users/feix_/iCloudDrive/Studium Master/CQM - Thesis Internship/Thesis-VariableEffects/RangerPredictFunction.R')
source('C:/Users/feix_/iCloudDrive/Studium Master/CQM - Thesis Internship/Thesis-VariableEffects/Helper.R')
set.seed(123)
N <- c(40) ; num.trees <- 20 ; reps <- 100; cor <- c(0)
k <- c(0.2, 1); node_size <- c(1)
formulas <- c("2*x.1+4*x.2-3*x.3+2.2*x.4-1.5*x.5")
longest_latex_formula <- "2x_1+4x_2-3x_3+2.2x_4-1.5x_5"
scenarios <- data.frame(expand.grid(N, num.trees, formulas, reps,
cor, k, node_size))
colnames(scenarios) = c("N", "N_Trees", "Formula", "Reps",
"Correlation", "k", "Node_Size")
scenarios$k_idx <- (scenarios$k == unique(scenarios$k)[1])
scenarios[,"Formula"] <- as.character(scenarios[,"Formula"]) ### Formula became Factor
scenarios["Longest_Latex_formula"] <- longest_latex_formula
scenarios <- split(scenarios, seq(nrow(scenarios)))
sim <- function(scenario){
k <- scenario[['k']]
N <- scenario[['N']]
num.trees <- scenario[['N_Trees']]
cor <- scenario[['Correlation']]
formula <- scenario[['Formula']]
node_size <- scenario[['Node_Size']]
reps <- scenario[['Reps']]
### Simulate Data
n_vars <- length(unique(unlist(str_extract_all(formula,"x.[0-9]+")))) # Number of variables
if (n_vars == 1) {
# Normal Distribution with Mean 0 and Variance 1
x <- data.frame(x.1 = rnorm(N, 0, 1))
} else{
# Multivariate Normal Distribution with Mean Vector 0 and diagonal Variance Covariance Matrix
x <- data.frame(x = rmvnorm(N, mean = rep(0, n_vars), sigma = CSgenerate(n_vars, cor)))
}
# Get interaction terms
all_terms_t <- unlist(strsplit(formula, "(?<=.)(?=[+])|(?<=.)(?=[-])",perl = TRUE))
all_terms <- character()
idx <- 1
for (term in 1:length(all_terms_t)) {
if ((str_count(all_terms_t[term],"\\(") >= 1) & (str_count(all_terms_t[term],"\\)") == 0)) {
all_terms[idx] <- paste0(all_terms_t[term], all_terms_t[term+1])
idx = idx + 1
} else if ((str_count(all_terms_t[term],"\\(") == 0) & (str_count(all_terms_t[term],"\\)") >= 1)){
} else {
all_terms[idx] <- all_terms_t[term]
idx <- idx + 1
}
}
n_coefs <- length(all_terms)
for (term in all_terms) {
if (length(unique(unlist(str_extract_all(term,"x.[0-9]+")))) > 1) {
interaction_term <- unique(unlist(str_extract_all(term,"x.[0-9]+")))
}
}
formula_p <- parse(text = formula)
y <- eval(formula_p, x) + rnorm(N, 0, 1)
data <- data.frame(cbind(x, y))
# Estimated Variable Means
x_bar <- colMeans(x)
# True Variable Means and Standard Deviations
true_mean <- rep(x = 0, times = n_vars)
names(true_mean) <- unique(unlist(str_extract_all(formula,"x.[0-9]+")))
true_s <- rep(x = 1, times = n_vars)
names(true_s) <- unique(unlist(str_extract_all(formula,"x.[0-9]+")))
list_names <- c('effects.rf','effects.f.true', 'effects.se.rf')
result_list <- vector(mode = 'list', length = length(list_names))
result_list <- lapply(X = 1:length(list_names), FUN = function(x){
init <- matrix(data = 0, nrow = reps, ncol = n_coefs)
colnames(init) <- extract_terms(formula)
result_list[[x]] <- init
})
names(result_list) <- list_names
for (rep in 1:reps) {
rf <- ranger( formula = y ~ .,
data = data,
num.trees = num.trees,
keep.inbag = T,
oob.error = F, # Save computational time
min.node.size = node_size)
var_effects <- numeric(n_coefs)
var_effects_se <- numeric(n_coefs)
var_effects_true <- numeric(n_coefs)
for (v in 1:n_coefs) {
# New data points based on estimated variable means and standard deviations
x_a <- replace(x_bar, v, x_bar[v] - k*sd(x[,v]))
x_b <- replace(x_bar, v, x_bar[v] + k*sd(x[,v]))
# New data points based on true variable means and standard deviations
x_a.true <- replace(true_mean, v, true_mean[v] - k*true_s[v])
x_b.true <- replace(true_mean, v, true_mean[v] + k*true_s[v])
new_data <- data.frame(rbind(x_a, x_b))
new_data.true <- data.frame(rbind(x_a.true, x_b.true))
rf.predict <- RangerForestPredict(rf$forest,
new_data,
type='se',
se.method = 'jack_cov',
predict.all = T,
inbag.counts = rf$inbag.counts)
# Using f_hat and sample mean&variance of X
predictions.rf <- rowMeans(rf.predict$predictions)
# Using f and true mean&variance of X
predictions.f.true <- eval(formula_p, new_data.true)
# Using f_hat predictions based on sample mean&variance of X
var_effects[v] <- (predictions.rf[2] - predictions.rf[1]) / (2*k*sd(x[,v]))
# Using f predictions based on true mean&variance of X
var_effects_true[v] <- (predictions.f.true[2] - predictions.f.true[1]) / (2*k*true_s[v])
effect.var <- pmax((rf.predict$cov[1,1] + rf.predict$cov[2,2]
- 2*rf.predict$cov[1,2]) /  (2*k*sd(x[,v]))^2, 0)
var_effects_se[v] <- sqrt(effect.var)
if (exists('interaction_term')) {
if (v == as.numeric(gsub(".*?([0-9]+).*", "\\1", interaction_term[1]))) {
# New data points based on estimated variable means and standard deviations
x_a <- replace(x_bar, v, x_bar[v] - k*sd(x[,v]))
x_b <- replace(x_bar, v, x_bar[v] + k*sd(x[,v]))
# New data points based on true variable means and standard deviations
x_a.true <- replace(true_mean, v, true_mean[v] - k*true_s[v])
x_b.true <- replace(true_mean, v, true_mean[v] + k*true_s[v])
x_a1 <- replace(x_a, n_vars, x_bar[v] - k*sd(x[,v]))
x_b1 <- replace(x_b, n_vars, x_bar[v] - k*sd(x[,v]))
x_a2 <- replace(x_a, n_vars, x_bar[v] + k*sd(x[,v]))
x_b2 <- replace(x_b, n_vars, x_bar[v] + k*sd(x[,v]))
x_a1.true <- replace(x_a.true, n_vars, true_mean[v] - k*true_s[v])
x_b1.true <- replace(x_b.true, n_vars, true_mean[v] - k*true_s[v])
x_a2.true <- replace(x_a.true, n_vars, true_mean[v] + k*true_s[v])
x_b2.true <- replace(x_b.true, n_vars, true_mean[v] + k*true_s[v])
new_data <- data.frame(rbind(x_a, x_b,
x_a1, x_b1,
x_a2, x_b2))
new_data.true <- data.frame(rbind(x_a.true, x_b.true,
x_a1.true, x_b1.true,
x_a2.true, x_b2.true))
rf.predict <- RangerForestPredict(rf$forest,
new_data,
type='se',
se.method = 'jack_cov',
predict.all = T,
inbag.counts = rf$inbag.counts)
### Computing Predictions
# Using f_hat and sample mean&variance of X
predictions.rf <- rowMeans(rf.predict$predictions)
# Using f and true mean&variance of X
predictions.f.true <- eval(formula_p, new_data.true)
var_effects[v] <- ((predictions.rf[5] - predictions.rf[3]) - (predictions.rf[6] - predictions.rf[4])) / (-4*k^2*sd(x[,interaction_term[1]])*sd(x[,interaction_term[2]]))
var_effects_true[v] <- ((predictions.f.true[5] - predictions.f.true[3]) - (predictions.f.true[6] - predictions.f.true[4])) / (-4*k^2*true_s[interaction_term[1]]*true_s[interaction_term[2]])
effect.var <- pmax((sum(diag(rf.predict$cov))
- 2*rf.predict$cov[2,1]
- 2*rf.predict$cov[3,1] + 2*rf.predict$cov[3,2]
+ 2*rf.predict$cov[4,1] - 2*rf.predict$cov[4,2] - 2*rf.predict$cov[4,3]) /  ((-4*k^2*sd(x[,interaction_term[1]])*sd(x[,interaction_term[2]])))^2, 0)
var_effects_se[v] <- sqrt(effect.var)
}
}
}
result_list[['effects.rf']][rep,] <- var_effects
result_list[['effects.f.true']][rep,] <- var_effects_true
result_list[['effects.se.rf']][rep,] <- var_effects_se
}
return(result_list)
}
res <- lapply(scenarios, sim)
res
